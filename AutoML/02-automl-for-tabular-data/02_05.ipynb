{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATOP</th>\n",
       "      <th>FLTID</th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>AC</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>TU 0712</td>\n",
       "      <td>CMN</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-03 10:30:00</td>\n",
       "      <td>2016-01-03 12.55.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>TU 0757</td>\n",
       "      <td>MXP</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-01-13 15:05:00</td>\n",
       "      <td>2016-01-13 16.55.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 31BIMO</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>TU 0214</td>\n",
       "      <td>TUN</td>\n",
       "      <td>IST</td>\n",
       "      <td>2016-01-16 04:10:00</td>\n",
       "      <td>2016-01-16 06.45.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0480</td>\n",
       "      <td>DJE</td>\n",
       "      <td>NTE</td>\n",
       "      <td>2016-01-17 14:10:00</td>\n",
       "      <td>2016-01-17 17.00.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>TU 0338</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ALG</td>\n",
       "      <td>2016-01-17 14:30:00</td>\n",
       "      <td>2016-01-17 15.50.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 320IMU</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID       DATOP     FLTID DEPSTN ARRSTN                  STD  \\\n",
       "0  train_id_0  2016-01-03  TU 0712     CMN    TUN  2016-01-03 10:30:00   \n",
       "1  train_id_1  2016-01-13  TU 0757     MXP    TUN  2016-01-13 15:05:00   \n",
       "2  train_id_2  2016-01-16  TU 0214     TUN    IST  2016-01-16 04:10:00   \n",
       "3  train_id_3  2016-01-17  TU 0480     DJE    NTE  2016-01-17 14:10:00   \n",
       "4  train_id_4  2016-01-17  TU 0338     TUN    ALG  2016-01-17 14:30:00   \n",
       "\n",
       "                   STA STATUS         AC  target  \n",
       "0  2016-01-03 12.55.00    ATA  TU 32AIMN   260.0  \n",
       "1  2016-01-13 16.55.00    ATA  TU 31BIMO    20.0  \n",
       "2  2016-01-16 06.45.00    ATA  TU 32AIMN     0.0  \n",
       "3  2016-01-17 17.00.00    ATA  TU 736IOK     0.0  \n",
       "4  2016-01-17 15.50.00    ATA  TU 320IMU    22.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Download the suggested data from Zindi\n",
    "# https://zindi.africa/competitions/ai-tunisia-hack-5-predictive-analytics-challenge-2\n",
    "data = TabularDataset(\"data/Train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATOP</th>\n",
       "      <th>FLTID</th>\n",
       "      <th>DEPSTN</th>\n",
       "      <th>ARRSTN</th>\n",
       "      <th>STD</th>\n",
       "      <th>STA</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>AC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_id_0</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>TU 0700</td>\n",
       "      <td>DJE</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-05-04 06:40:00</td>\n",
       "      <td>2016-05-04 07.30.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_id_1</td>\n",
       "      <td>2016-05-05</td>\n",
       "      <td>TU 0395</td>\n",
       "      <td>TUN</td>\n",
       "      <td>BKO</td>\n",
       "      <td>2016-05-05 15:20:00</td>\n",
       "      <td>2016-05-05 20.05.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 320IMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_id_2</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>TU 0745</td>\n",
       "      <td>FRA</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-05-06 10:00:00</td>\n",
       "      <td>2016-05-06 12.25.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_id_3</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>TU 0848</td>\n",
       "      <td>BEY</td>\n",
       "      <td>TUN</td>\n",
       "      <td>2016-05-11 09:40:00</td>\n",
       "      <td>2016-05-11 13.10.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 31BIMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_id_4</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>TU 0635</td>\n",
       "      <td>ORY</td>\n",
       "      <td>MIR</td>\n",
       "      <td>2016-05-11 09:50:00</td>\n",
       "      <td>2016-05-11 12.35.00</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID       DATOP     FLTID DEPSTN ARRSTN                  STD  \\\n",
       "0  test_id_0  2016-05-04  TU 0700     DJE    TUN  2016-05-04 06:40:00   \n",
       "1  test_id_1  2016-05-05  TU 0395     TUN    BKO  2016-05-05 15:20:00   \n",
       "2  test_id_2  2016-05-06  TU 0745     FRA    TUN  2016-05-06 10:00:00   \n",
       "3  test_id_3  2016-05-11  TU 0848     BEY    TUN  2016-05-11 09:40:00   \n",
       "4  test_id_4  2016-05-11  TU 0635     ORY    MIR  2016-05-11 09:50:00   \n",
       "\n",
       "                   STA STATUS         AC  \n",
       "0  2016-05-04 07.30.00    ATA  TU 32AIMF  \n",
       "1  2016-05-05 20.05.00    ATA  TU 320IMW  \n",
       "2  2016-05-06 12.25.00    ATA  TU 32AIMC  \n",
       "3  2016-05-11 13.10.00    ATA  TU 31BIMO  \n",
       "4  2016-05-11 12.35.00    ATA  TU 736IOQ  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = TabularDataset(\"data/Test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'target'\n",
    "\n",
    "SAVE_PATH = 'AutoGluonModels_exercise'\n",
    "\n",
    "EVAL_METRIC = 'root_mean_squared_error'\n",
    "\n",
    "PROBLEM_TYPE = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the Tabular Predictor and enable bagging\n",
    "predictor = TabularPredictor(label=LABEL, problem_type=PROBLEM_TYPE, path=SAVE_PATH, eval_metric=EVAL_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutoGluonModels_exercise/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.1.0: Sun Oct  9 20:15:09 PDT 2022; root:xnu-8792.41.9~2/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   188.39 GB / 494.38 GB (38.1%)\n",
      "Train Data Rows:    75483\n",
      "Train Data Columns: 9\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    804.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.37 MB (5.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 5.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])                     : 6 | ['FLTID', 'DEPSTN', 'ARRSTN', 'STA', 'STATUS', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 2 | ['DATOP', 'STD']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 6 | ['FLTID', 'DEPSTN', 'ARRSTN', 'STA', 'STATUS', ...]\n",
      "\t\t('int', ['datetime_as_int']) : 6 | ['DATOP', 'DATOP.year', 'DATOP.month', 'DATOP.day', 'DATOP.dayofweek', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t8 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.23 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 199.21s of the 298.89s of remaining time.\n",
      "\t-121.6851\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 195.89s of the 295.57s of remaining time.\n",
      "\t-135.281\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 195.49s of the 295.17s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel. A quick tip is to install via `pip install ray==2.2.0`, or use sequential fold fitting by passing `sequential_local` to `ag_args_ensemble` when calling tabular.fitFor example: `predictor.fit(..., ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 979. Best iteration is:\n",
      "\t[978]\tvalid_set's rmse: 106.622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 106.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1140. Best iteration is:\n",
      "\t[1138]\tvalid_set's rmse: 106.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 113.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1227. Best iteration is:\n",
      "\t[1227]\tvalid_set's rmse: 113.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 105.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1290. Best iteration is:\n",
      "\t[1180]\tvalid_set's rmse: 105.201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 106.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1216. Best iteration is:\n",
      "\t[1205]\tvalid_set's rmse: 106.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 117.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1200. Best iteration is:\n",
      "\t[1042]\tvalid_set's rmse: 117.438\n",
      "\t-109.2523\t = Validation score   (-root_mean_squared_error)\n",
      "\t178.39s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 16.0s of the 115.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 67. Best iteration is:\n",
      "\t[67]\tvalid_set's rmse: 109.213\n",
      "\tRan out of time, early stopping on iteration 83. Best iteration is:\n",
      "\t[83]\tvalid_set's rmse: 107.441\n",
      "\tRan out of time, early stopping on iteration 66. Best iteration is:\n",
      "\t[66]\tvalid_set's rmse: 114.364\n",
      "\tRan out of time, early stopping on iteration 84. Best iteration is:\n",
      "\t[84]\tvalid_set's rmse: 114.757\n",
      "\tRan out of time, early stopping on iteration 84. Best iteration is:\n",
      "\t[84]\tvalid_set's rmse: 105.292\n",
      "\tRan out of time, early stopping on iteration 93. Best iteration is:\n",
      "\t[91]\tvalid_set's rmse: 105.901\n",
      "\tRan out of time, early stopping on iteration 109. Best iteration is:\n",
      "\t[108]\tvalid_set's rmse: 116.821\n",
      "\tRan out of time, early stopping on iteration 125. Best iteration is:\n",
      "\t[125]\tvalid_set's rmse: 102.983\n",
      "\t-109.7005\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.24s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.55s of the 100.23s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 60 due to low memory. Expected memory usage reduced from 74.24% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 4.6s to train, which exceeds the maximum time limit of 0.6s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 0.22s of the 99.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 0.06s of the 99.74s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 59 due to low memory. Expected memory usage reduced from 75.3% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 1.2s to train, which exceeds the maximum time limit of 0.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 298.9s of the 99.63s of remaining time.\n",
      "\t-108.3977\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 99.34s of the 99.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 673. Best iteration is:\n",
      "\t[643]\tvalid_set's rmse: 111.805\n",
      "\t-108.3378\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.93s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 66.14s of the 66.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 359. Best iteration is:\n",
      "\t[356]\tvalid_set's rmse: 109.753\n",
      "\tRan out of time, early stopping on iteration 405. Best iteration is:\n",
      "\t[404]\tvalid_set's rmse: 118.966\n",
      "\t-108.1951\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.83s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 39.07s of the 39.06s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 55 due to low memory. Expected memory usage reduced from 81.21% -> 15.0% of available memory...\n",
      "\t-111.8936\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.87s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 33.59s of the 33.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 180.\n",
      "\tRan out of time, early stopping on iteration 173.\n",
      "\tRan out of time, early stopping on iteration 231.\n",
      "\tRan out of time, early stopping on iteration 412.\n",
      "\tRan out of time, early stopping on iteration 488.\n",
      "\t-107.9209\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.47s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1.85s of the 1.85s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 53 due to low memory. Expected memory usage reduced from 83.74% -> 15.0% of available memory...\n",
      "\t-110.898\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 0.42s of the 0.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.8.2`. \n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 0.37s of the 0.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tMismatched version between the Python package and the native shared object.  Python package version: 1.7.6. Shared object version: 1.5.1. Shared object is loaded from: /Users/robertandrewstevens/opt/anaconda3/lib/libxgboost.dylib.\n",
      "Likely cause:\n",
      "  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 121, in _fit\n",
      "    try_import_xgboost()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 138, in try_import_xgboost\n",
      "    import xgboost\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/__init__.py\", line 7, in <module>\n",
      "    from . import collective, dask, rabit\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/collective.py\", line 12, in <module>\n",
      "    from .core import _LIB, _check_call, c_str, py_str, from_pystr_to_cstr\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 264, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 258, in _load_lib\n",
      "    raise ValueError(msg)\n",
      "ValueError: Mismatched version between the Python package and the native shared object.  Python package version: 1.7.6. Shared object version: 1.5.1. Shared object is loaded from: /Users/robertandrewstevens/opt/anaconda3/lib/libxgboost.dylib.\n",
      "Likely cause:\n",
      "  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 0.04s of the 0.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 298.9s of the -0.02s of remaining time.\n",
      "\t-107.2584\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 300.37s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonModels_exercise/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fd751f42610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(train, presets=[\"best_quality\"], time_limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-105.522757</td>\n",
       "      <td>-107.258376</td>\n",
       "      <td>3.398777</td>\n",
       "      <td>2.396626</td>\n",
       "      <td>261.344192</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.327087</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-105.746866</td>\n",
       "      <td>-108.195057</td>\n",
       "      <td>2.942437</td>\n",
       "      <td>1.247340</td>\n",
       "      <td>223.801257</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.126526</td>\n",
       "      <td>26.832954</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-105.869471</td>\n",
       "      <td>-107.920917</td>\n",
       "      <td>2.949300</td>\n",
       "      <td>1.290345</td>\n",
       "      <td>228.435690</td>\n",
       "      <td>0.245499</td>\n",
       "      <td>0.169531</td>\n",
       "      <td>31.467387</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-106.227761</td>\n",
       "      <td>-108.337835</td>\n",
       "      <td>3.078805</td>\n",
       "      <td>1.271245</td>\n",
       "      <td>229.898839</td>\n",
       "      <td>0.375004</td>\n",
       "      <td>0.150432</td>\n",
       "      <td>32.930537</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-106.766788</td>\n",
       "      <td>-108.397743</td>\n",
       "      <td>2.706238</td>\n",
       "      <td>1.121404</td>\n",
       "      <td>197.248015</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.279712</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-107.183961</td>\n",
       "      <td>-110.897980</td>\n",
       "      <td>2.811389</td>\n",
       "      <td>1.582137</td>\n",
       "      <td>197.846271</td>\n",
       "      <td>0.107588</td>\n",
       "      <td>0.461323</td>\n",
       "      <td>0.877968</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-107.505786</td>\n",
       "      <td>-109.700495</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>15.239797</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>15.239797</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-107.533192</td>\n",
       "      <td>-109.252292</td>\n",
       "      <td>2.282588</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>178.387318</td>\n",
       "      <td>2.282588</td>\n",
       "      <td>0.695364</td>\n",
       "      <td>178.387318</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-108.538172</td>\n",
       "      <td>-111.893581</td>\n",
       "      <td>2.804913</td>\n",
       "      <td>1.638589</td>\n",
       "      <td>201.838796</td>\n",
       "      <td>0.101112</td>\n",
       "      <td>0.517775</td>\n",
       "      <td>4.870493</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-120.810947</td>\n",
       "      <td>-121.685058</td>\n",
       "      <td>0.056945</td>\n",
       "      <td>0.127599</td>\n",
       "      <td>3.156226</td>\n",
       "      <td>0.056945</td>\n",
       "      <td>0.127599</td>\n",
       "      <td>3.156226</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-134.758141</td>\n",
       "      <td>-135.281044</td>\n",
       "      <td>0.088868</td>\n",
       "      <td>0.189121</td>\n",
       "      <td>0.184962</td>\n",
       "      <td>0.088868</td>\n",
       "      <td>0.189121</td>\n",
       "      <td>0.184962</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test   score_val  pred_time_test  \\\n",
       "0      WeightedEnsemble_L3 -105.522757 -107.258376        3.398777   \n",
       "1          LightGBM_BAG_L2 -105.746866 -108.195057        2.942437   \n",
       "2          CatBoost_BAG_L2 -105.869471 -107.920917        2.949300   \n",
       "3        LightGBMXT_BAG_L2 -106.227761 -108.337835        3.078805   \n",
       "4      WeightedEnsemble_L2 -106.766788 -108.397743        2.706238   \n",
       "5     ExtraTreesMSE_BAG_L2 -107.183961 -110.897980        2.811389   \n",
       "6          LightGBM_BAG_L1 -107.505786 -109.700495        0.275400   \n",
       "7        LightGBMXT_BAG_L1 -107.533192 -109.252292        2.282588   \n",
       "8   RandomForestMSE_BAG_L2 -108.538172 -111.893581        2.804913   \n",
       "9    KNeighborsUnif_BAG_L1 -120.810947 -121.685058        0.056945   \n",
       "10   KNeighborsDist_BAG_L1 -134.758141 -135.281044        0.088868   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        2.396626  261.344192                 0.002141   \n",
       "1        1.247340  223.801257                 0.238636   \n",
       "2        1.290345  228.435690                 0.245499   \n",
       "3        1.271245  229.898839                 0.375004   \n",
       "4        1.121404  197.248015                 0.002437   \n",
       "5        1.582137  197.846271                 0.107588   \n",
       "6        0.108729   15.239797                 0.275400   \n",
       "7        0.695364  178.387318                 2.282588   \n",
       "8        1.638589  201.838796                 0.101112   \n",
       "9        0.127599    3.156226                 0.056945   \n",
       "10       0.189121    0.184962                 0.088868   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000657           0.327087            3       True   \n",
       "1                 0.126526          26.832954            2       True   \n",
       "2                 0.169531          31.467387            2       True   \n",
       "3                 0.150432          32.930537            2       True   \n",
       "4                 0.000590           0.279712            2       True   \n",
       "5                 0.461323           0.877968            2       True   \n",
       "6                 0.108729          15.239797            1       True   \n",
       "7                 0.695364         178.387318            1       True   \n",
       "8                 0.517775           4.870493            2       True   \n",
       "9                 0.127599           3.156226            1       True   \n",
       "10                0.189121           0.184962            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          11  \n",
       "1           7  \n",
       "2           9  \n",
       "3           6  \n",
       "4           5  \n",
       "5          10  \n",
       "6           4  \n",
       "7           3  \n",
       "8           8  \n",
       "9           1  \n",
       "10          2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(val, extra_info=False, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14.908741\n",
       "1    35.603611\n",
       "2    24.584660\n",
       "3    13.048778\n",
       "4    25.833878\n",
       "Name: target, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make predictions on the test set\n",
    "predictions = predictor.predict(test)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutoGluonModels_exercise_hpt/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.1.0: Sun Oct  9 20:15:09 PDT 2022; root:xnu-8792.41.9~2/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   188.07 GB / 494.38 GB (38.0%)\n",
      "Train Data Rows:    75483\n",
      "Train Data Columns: 9\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    695.5 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.37 MB (6.5% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 6.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])                     : 6 | ['FLTID', 'DEPSTN', 'ARRSTN', 'STA', 'STATUS', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 2 | ['DATOP', 'STD']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 6 | ['FLTID', 'DEPSTN', 'ARRSTN', 'STA', 'STATUS', ...]\n",
      "\t\t('int', ['datetime_as_int']) : 6 | ['DATOP', 'DATOP.year', 'DATOP.month', 'DATOP.day', 'DATOP.dayofweek', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t8 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.23 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{'max_depth': 6}],\n",
      "\t'GBM': [{'max_depth': 6}],\n",
      "\t'XGB': [{'max_depth': 12}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 199.21s of the 298.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 658. Best iteration is:\n",
      "\t[658]\tvalid_set's rmse: 104.433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 111.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1399. Best iteration is:\n",
      "\t[1239]\tvalid_set's rmse: 111.737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 103.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-107.2417\t = Validation score   (-root_mean_squared_error)\n",
      "\t120.94s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 77.45s of the 177.13s of remaining time.\n",
      "\t-113.9866\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.28s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 73.16s of the 172.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tMismatched version between the Python package and the native shared object.  Python package version: 1.7.6. Shared object version: 1.5.1. Shared object is loaded from: /Users/robertandrewstevens/opt/anaconda3/lib/libxgboost.dylib.\n",
      "Likely cause:\n",
      "  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 121, in _fit\n",
      "    try_import_xgboost()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 138, in try_import_xgboost\n",
      "    import xgboost\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/__init__.py\", line 7, in <module>\n",
      "    from . import collective, dask, rabit\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/collective.py\", line 12, in <module>\n",
      "    from .core import _LIB, _check_call, c_str, py_str, from_pystr_to_cstr\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 264, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 258, in _load_lib\n",
      "    raise ValueError(msg)\n",
      "ValueError: Mismatched version between the Python package and the native shared object.  Python package version: 1.7.6. Shared object version: 1.5.1. Shared object is loaded from: /Users/robertandrewstevens/opt/anaconda3/lib/libxgboost.dylib.\n",
      "Likely cause:\n",
      "  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 298.89s of the 172.58s of remaining time.\n",
      "\t-107.053\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 3 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 172.35s of the 172.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 115.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 1735. Best iteration is:\n",
      "\t[1696]\tvalid_set's rmse: 115.568\n",
      "\t-107.1817\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.59s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 136.36s of the 136.36s of remaining time.\n",
      "\t-106.7927\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.44s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 129.86s of the 129.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tMismatched version between the Python package and the native shared object.  Python package version: 1.7.6. Shared object version: 1.5.1. Shared object is loaded from: /Users/robertandrewstevens/opt/anaconda3/lib/libxgboost.dylib.\n",
      "Likely cause:\n",
      "  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 121, in _fit\n",
      "    try_import_xgboost()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/autogluon/common/utils/try_import.py\", line 138, in try_import_xgboost\n",
      "    import xgboost\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/__init__.py\", line 7, in <module>\n",
      "    from . import collective, dask, rabit\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/collective.py\", line 12, in <module>\n",
      "    from .core import _LIB, _check_call, c_str, py_str, from_pystr_to_cstr\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 264, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/robertandrewstevens/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 258, in _load_lib\n",
      "    raise ValueError(msg)\n",
      "ValueError: Mismatched version between the Python package and the native shared object.  Python package version: 1.7.6. Shared object version: 1.5.1. Shared object is loaded from: /Users/robertandrewstevens/opt/anaconda3/lib/libxgboost.dylib.\n",
      "Likely cause:\n",
      "  * XGBoost is first installed with anaconda then upgraded with pip. To fix it please remove one of the installations.\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 129.59s of the 129.59s of remaining time.\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-106.9375\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.97s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 106.01s of the 106.0s of remaining time.\n",
      "\tFitting 8 child models (S3F1 - S3F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 862. Best iteration is:\n",
      "\t[671]\tvalid_set's rmse: 117.028\n",
      "\t-106.9976\t = Validation score   (-root_mean_squared_error)\n",
      "\t84.55s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Repeating k-fold bagging: 4/20\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 80.19s of the 80.19s of remaining time.\n",
      "\tFitting 8 child models (S4F1 - S4F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 839. Best iteration is:\n",
      "\t[839]\tvalid_set's rmse: 111.132\n",
      "\t-106.955\t = Validation score   (-root_mean_squared_error)\n",
      "\t107.73s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Repeating k-fold bagging: 5/20\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 56.76s of the 56.75s of remaining time.\n",
      "\tFitting 8 child models (S5F1 - S5F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-106.9784\t = Validation score   (-root_mean_squared_error)\n",
      "\t129.68s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Repeating k-fold bagging: 6/20\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 34.56s of the 34.55s of remaining time.\n",
      "\tFitting 8 child models (S6F1 - S6F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 231. Best iteration is:\n",
      "\t[192]\tvalid_set's rmse: 102.584\n",
      "\tRan out of time, early stopping on iteration 275. Best iteration is:\n",
      "\t[258]\tvalid_set's rmse: 110.295\n",
      "\t-107.0071\t = Validation score   (-root_mean_squared_error)\n",
      "\t147.05s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Completed 6/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 298.89s of the 16.98s of remaining time.\n",
      "\t-106.4052\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 283.27s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonModels_exercise_hpt/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_hpt = TabularPredictor(label=LABEL, problem_type=PROBLEM_TYPE, path=SAVE_PATH + \"_hpt\", eval_metric=EVAL_METRIC).fit(\n",
    "    train, presets=['best_quality'], time_limit=300, hyperparameters={\n",
    "        'RF': [{'max_depth': 6}],\n",
    "        'GBM': [{'max_depth': 6}],\n",
    "        'XGB': [{'max_depth': 12}]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-104.213435</td>\n",
       "      <td>-106.405201</td>\n",
       "      <td>3.656308</td>\n",
       "      <td>3.314956</td>\n",
       "      <td>276.936189</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.226550</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_BAG_L2</td>\n",
       "      <td>-104.554120</td>\n",
       "      <td>-106.792744</td>\n",
       "      <td>1.633921</td>\n",
       "      <td>2.460040</td>\n",
       "      <td>129.655216</td>\n",
       "      <td>0.065004</td>\n",
       "      <td>1.007212</td>\n",
       "      <td>5.444364</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-104.777283</td>\n",
       "      <td>-107.007141</td>\n",
       "      <td>3.589678</td>\n",
       "      <td>2.307159</td>\n",
       "      <td>271.265275</td>\n",
       "      <td>2.020761</td>\n",
       "      <td>0.854331</td>\n",
       "      <td>147.054422</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-105.171481</td>\n",
       "      <td>-107.241746</td>\n",
       "      <td>1.505674</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>120.935668</td>\n",
       "      <td>1.505674</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>120.935668</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-105.190387</td>\n",
       "      <td>-107.053045</td>\n",
       "      <td>1.571387</td>\n",
       "      <td>1.453407</td>\n",
       "      <td>124.438205</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.227353</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest_BAG_L1</td>\n",
       "      <td>-111.968044</td>\n",
       "      <td>-113.986639</td>\n",
       "      <td>0.063243</td>\n",
       "      <td>0.967818</td>\n",
       "      <td>3.275184</td>\n",
       "      <td>0.063243</td>\n",
       "      <td>0.967818</td>\n",
       "      <td>3.275184</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test   score_val  pred_time_test  pred_time_val  \\\n",
       "0  WeightedEnsemble_L3 -104.213435 -106.405201        3.656308       3.314956   \n",
       "1  RandomForest_BAG_L2 -104.554120 -106.792744        1.633921       2.460040   \n",
       "2      LightGBM_BAG_L2 -104.777283 -107.007141        3.589678       2.307159   \n",
       "3      LightGBM_BAG_L1 -105.171481 -107.241746        1.505674       0.485010   \n",
       "4  WeightedEnsemble_L2 -105.190387 -107.053045        1.571387       1.453407   \n",
       "5  RandomForest_BAG_L1 -111.968044 -113.986639        0.063243       0.967818   \n",
       "\n",
       "     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  276.936189                 0.001626                0.000585   \n",
       "1  129.655216                 0.065004                1.007212   \n",
       "2  271.265275                 2.020761                0.854331   \n",
       "3  120.935668                 1.505674                0.485010   \n",
       "4  124.438205                 0.002470                0.000579   \n",
       "5    3.275184                 0.063243                0.967818   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.226550            3       True          6  \n",
       "1           5.444364            2       True          5  \n",
       "2         147.054422            2       True          4  \n",
       "3         120.935668            1       True          1  \n",
       "4           0.227353            2       True          3  \n",
       "5           3.275184            1       True          2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_hpt.leaderboard(val, extra_info=False, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14.908741\n",
       "1    35.603611\n",
       "2    24.584660\n",
       "3    13.048778\n",
       "4    25.833878\n",
       "Name: target, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(test)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: data/SampleSubmission.csv | Columns = 2 / 2 | Rows = 9333 -> 9333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_id_0</td>\n",
       "      <td>2470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_id_1</td>\n",
       "      <td>2944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_id_2</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_id_3</td>\n",
       "      <td>3264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_id_4</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  target\n",
       "0  test_id_0    2470\n",
       "1  test_id_1    2944\n",
       "2  test_id_2    2585\n",
       "3  test_id_3    3264\n",
       "4  test_id_4    1369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = TabularDataset(\"data/SampleSubmission.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"data/submssion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cfc447b3686aa72f4379f2e431f1434f0aba1b4c719ad370f525d6d72336906e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
