{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.core.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset('../01-machine-learning-recap/data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>YearOfObservation</th>\n",
       "      <th>Insured_Period</th>\n",
       "      <th>Residential</th>\n",
       "      <th>Building_Painted</th>\n",
       "      <th>Building_Fenced</th>\n",
       "      <th>Garden</th>\n",
       "      <th>Settlement</th>\n",
       "      <th>Building Dimension</th>\n",
       "      <th>Building_Type</th>\n",
       "      <th>Date_of_Occupancy</th>\n",
       "      <th>NumberOfWindows</th>\n",
       "      <th>Geo_Code</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H14663</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>U</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>.</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H2037</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>V</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H3802</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>U</td>\n",
       "      <td>595.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>.</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H3834</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>U</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>.</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5053</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>V</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>R</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer Id  YearOfObservation  Insured_Period  Residential  \\\n",
       "0      H14663               2013             1.0            0   \n",
       "1       H2037               2015             1.0            0   \n",
       "2       H3802               2014             1.0            0   \n",
       "3       H3834               2013             1.0            0   \n",
       "4       H5053               2014             1.0            0   \n",
       "\n",
       "  Building_Painted Building_Fenced Garden Settlement  Building Dimension  \\\n",
       "0                N               V      V          U               290.0   \n",
       "1                V               N      O          R               490.0   \n",
       "2                N               V      V          U               595.0   \n",
       "3                V               V      V          U              2840.0   \n",
       "4                V               N      O          R               680.0   \n",
       "\n",
       "   Building_Type  Date_of_Occupancy NumberOfWindows Geo_Code  Claim  \n",
       "0              1             1960.0               .     1053      0  \n",
       "1              1             1850.0               4     1053      0  \n",
       "2              1             1960.0               .     1053      0  \n",
       "3              1             1960.0               .     1053      0  \n",
       "4              1             1800.0               3     1053      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_data, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRIC = \"f1\"\n",
    "SAVE_PATH = \"AutoGluonModels_improved\"   # Trained models will be saved here\n",
    "LABEL = \"Claim\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your AutoGluon Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Via Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"age_of_building\"] = train[\"YearOfObservation\"] - train[\"Date_of_Occupancy\"]\n",
    "test[\"age_of_building\"] = test[\"YearOfObservation\"] - test[\"Date_of_Occupancy\"]\n",
    "train[\"YearOfObservation\"] = train[\"YearOfObservation\"].astype(\"category\")\n",
    "test[\"YearOfObservation\"] = test[\"YearOfObservation\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use the Right Preset & refit_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutoGluonModels_improved\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutoGluonModels_improved/\"\n",
      "AutoGluon Version:  0.4.2\n",
      "Python Version:     3.9.13\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    5012\n",
      "Train Data Columns: 14\n",
      "Label Column: Claim\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1657.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.33 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Customer Id']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Customer Id']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['YearOfObservation']\n",
      "\t\t('float', [])    : 4 | ['Insured_Period', 'Building Dimension', 'Date_of_Occupancy', 'age_of_building']\n",
      "\t\t('int', [])      : 2 | ['Residential', 'Building_Type']\n",
      "\t\t('object', [])   : 6 | ['Building_Painted', 'Building_Fenced', 'Garden', 'Settlement', 'NumberOfWindows', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['YearOfObservation', 'Garden', 'NumberOfWindows', 'Geo_Code']\n",
      "\t\t('float', [])     : 4 | ['Insured_Period', 'Building Dimension', 'Date_of_Occupancy', 'age_of_building']\n",
      "\t\t('int', [])       : 1 | ['Building_Type']\n",
      "\t\t('int', ['bool']) : 4 | ['Residential', 'Building_Painted', 'Building_Fenced', 'Settlement']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t0.2841\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t0.3284\t = Validation score   (f1)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.576084\tvalid_set's f1: 0.311111\n",
      "[1000]\tvalid_set's binary_logloss: 0.526968\tvalid_set's f1: 0.342857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.3527\t = Validation score   (f1)\n",
      "\t17.32s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.666168\tvalid_set's f1: 0.340611\n",
      "[1000]\tvalid_set's binary_logloss: 0.687778\tvalid_set's f1: 0.376569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.3661\t = Validation score   (f1)\n",
      "\t17.06s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.3269\t = Validation score   (f1)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.3257\t = Validation score   (f1)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.2872\t = Validation score   (f1)\n",
      "\t15.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.2969\t = Validation score   (f1)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.294\t = Validation score   (f1)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3795\t = Validation score   (f1)\n",
      "\t10.08s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.943168\tvalid_set's f1: 0.378855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.3702\t = Validation score   (f1)\n",
      "\t52.7s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3795\t = Validation score   (f1)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.530613\tvalid_set's f1: 0.377358\n",
      "[1000]\tvalid_set's binary_logloss: 0.535033\tvalid_set's f1: 0.412281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.4115\t = Validation score   (f1)\n",
      "\t25.02s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.635375\tvalid_set's f1: 0.4\n",
      "[1000]\tvalid_set's binary_logloss: 0.617671\tvalid_set's f1: 0.360976\n",
      "[1000]\tvalid_set's binary_logloss: 0.617313\tvalid_set's f1: 0.416667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.4007\t = Validation score   (f1)\n",
      "\t22.65s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t0.3497\t = Validation score   (f1)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t0.3346\t = Validation score   (f1)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.344\t = Validation score   (f1)\n",
      "\t22.28s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t0.3164\t = Validation score   (f1)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t0.3225\t = Validation score   (f1)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3971\t = Validation score   (f1)\n",
      "\t15.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 1.00116\tvalid_set's f1: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.4002\t = Validation score   (f1)\n",
      "\t71.16s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4115\t = Validation score   (f1)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 280.32s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.01s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.81s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t0.34s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.42s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t3.86s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.04s\t = Training   runtime\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutoGluonModels_improved/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=LABEL, path=SAVE_PATH, eval_metric=EVAL_METRIC)\n",
    "predictor = predictor.fit(train, presets=['best_quality'], time_limit=100, refit_full='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "      <th>num_features</th>\n",
       "      <th>...</th>\n",
       "      <th>child_model_type</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>hyperparameters_fit</th>\n",
       "      <th>ag_args_fit</th>\n",
       "      <th>features</th>\n",
       "      <th>child_hyperparameters</th>\n",
       "      <th>child_hyperparameters_fit</th>\n",
       "      <th>child_ag_args_fit</th>\n",
       "      <th>ancestors</th>\n",
       "      <th>descendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.411489</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>139.059122</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>25.023090</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>LGBModel</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[YearOfObservation, Building_Type, ExtraTreesG...</td>\n",
       "      <td>{'learning_rate': 0.05, 'extra_trees': True}</td>\n",
       "      <td>{'num_boost_round': 604}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...</td>\n",
       "      <td>[WeightedEnsemble_L3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.411489</td>\n",
       "      <td>0.923126</td>\n",
       "      <td>140.606223</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>1.547101</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>GreedyWeightedEnsembleModel</td>\n",
       "      <td>{'use_orig_features': False, 'max_base_models'...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[LightGBMXT_BAG_L2]</td>\n",
       "      <td>{'ensemble_size': 100}</td>\n",
       "      <td>{'ensemble_size': 1}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.400709</td>\n",
       "      <td>0.909987</td>\n",
       "      <td>136.682842</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>22.646810</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>LGBModel</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[YearOfObservation, Building_Type, ExtraTreesG...</td>\n",
       "      <td>{'learning_rate': 0.05}</td>\n",
       "      <td>{'num_boost_round': 555}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.400244</td>\n",
       "      <td>0.945984</td>\n",
       "      <td>185.196528</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>71.160496</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>LGBModel</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[YearOfObservation, Building_Type, ExtraTreesG...</td>\n",
       "      <td>{'learning_rate': 0.03, 'num_leaves': 128, 'fe...</td>\n",
       "      <td>{'num_boost_round': 474}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.397146</td>\n",
       "      <td>0.889858</td>\n",
       "      <td>129.272331</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>15.236298</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>XGBoostModel</td>\n",
       "      <td>{'use_orig_features': True, 'max_base_models':...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[YearOfObservation, Building_Type, ExtraTreesG...</td>\n",
       "      <td>{'n_estimators': 10000, 'learning_rate': 0.1, ...</td>\n",
       "      <td>{'n_estimators': 211}</td>\n",
       "      <td>{'max_memory_usage_ratio': 1.0, 'max_time_limi...</td>\n",
       "      <td>[ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val    fit_time  \\\n",
       "0     LightGBMXT_BAG_L2   0.411489       0.918000  139.059122   \n",
       "1   WeightedEnsemble_L3   0.411489       0.923126  140.606223   \n",
       "2       LightGBM_BAG_L2   0.400709       0.909987  136.682842   \n",
       "3  LightGBMLarge_BAG_L2   0.400244       0.945984  185.196528   \n",
       "4        XGBoost_BAG_L2   0.397146       0.889858  129.272331   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.074315          25.023090            2       True   \n",
       "1                0.005127           1.547101            3       True   \n",
       "2                0.066303          22.646810            2       True   \n",
       "3                0.102300          71.160496            2       True   \n",
       "4                0.046173          15.236298            2       True   \n",
       "\n",
       "   fit_order  num_features  ...             child_model_type  \\\n",
       "0         13            24  ...                     LGBModel   \n",
       "1         22             1  ...  GreedyWeightedEnsembleModel   \n",
       "2         14            24  ...                     LGBModel   \n",
       "3         21            24  ...                     LGBModel   \n",
       "4         20            24  ...                 XGBoostModel   \n",
       "\n",
       "                                     hyperparameters  hyperparameters_fit  \\\n",
       "0  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "1  {'use_orig_features': False, 'max_base_models'...                   {}   \n",
       "2  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "3  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "4  {'use_orig_features': True, 'max_base_models':...                   {}   \n",
       "\n",
       "                                         ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "3  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "4  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "\n",
       "                                            features  \\\n",
       "0  [YearOfObservation, Building_Type, ExtraTreesG...   \n",
       "1                                [LightGBMXT_BAG_L2]   \n",
       "2  [YearOfObservation, Building_Type, ExtraTreesG...   \n",
       "3  [YearOfObservation, Building_Type, ExtraTreesG...   \n",
       "4  [YearOfObservation, Building_Type, ExtraTreesG...   \n",
       "\n",
       "                               child_hyperparameters  \\\n",
       "0       {'learning_rate': 0.05, 'extra_trees': True}   \n",
       "1                             {'ensemble_size': 100}   \n",
       "2                            {'learning_rate': 0.05}   \n",
       "3  {'learning_rate': 0.03, 'num_leaves': 128, 'fe...   \n",
       "4  {'n_estimators': 10000, 'learning_rate': 0.1, ...   \n",
       "\n",
       "   child_hyperparameters_fit  \\\n",
       "0   {'num_boost_round': 604}   \n",
       "1       {'ensemble_size': 1}   \n",
       "2   {'num_boost_round': 555}   \n",
       "3   {'num_boost_round': 474}   \n",
       "4      {'n_estimators': 211}   \n",
       "\n",
       "                                   child_ag_args_fit  \\\n",
       "0  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "1  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "2  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "3  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "4  {'max_memory_usage_ratio': 1.0, 'max_time_limi...   \n",
       "\n",
       "                                           ancestors            descendants  \n",
       "0  [ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...  [WeightedEnsemble_L3]  \n",
       "1  [ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...                     []  \n",
       "2  [ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...                     []  \n",
       "3  [ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...                     []  \n",
       "4  [ExtraTreesEntr_BAG_L1, KNeighborsUnif_BAG_L1,...                     []  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(extra_info=True, silent=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Via CustomMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_cost = 1000  # Admin fees spent to investigate potential insurance claim\n",
    "fn_cost = 10000 # Average insurance claim made\n",
    "tp_cost = 1000 # Admin fees spent to investigate potential insurance claim\n",
    "tn_cost = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(y_true, y_prob):\n",
    "    tp = np.where((y_prob >= 0.7) & (y_true==1), tp_cost, 0)\n",
    "    fp = np.where((y_prob >= 0.7) & (y_true==0), fp_cost, 0)\n",
    "    tn = np.where((y_prob < 0.7) & (y_true==0), tn_cost, 0)\n",
    "    fn = np.where((y_prob < 0.7) & (y_true==1), fn_cost, 0)\n",
    "    return np.sum([tp,fp,tn,fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scorer = make_scorer(\n",
    "    name=\"operating_cost\",\n",
    "    score_func=cost_fn,\n",
    "    greater_is_better=False,\n",
    "    needs_proba=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>operating_cost</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>0.371108</td>\n",
       "      <td>-4157000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.855480</td>\n",
       "      <td>0.044924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.855480</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.349669</td>\n",
       "      <td>-4397000</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>0.211080</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>17.062408</td>\n",
       "      <td>0.211080</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>17.062408</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>0.348052</td>\n",
       "      <td>-4327000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809883</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.809883</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>0.346354</td>\n",
       "      <td>-4576000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>0.133158</td>\n",
       "      <td>0.398403</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>0.133158</td>\n",
       "      <td>0.398403</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.346354</td>\n",
       "      <td>-4576000</td>\n",
       "      <td>0.325664</td>\n",
       "      <td>0.101776</td>\n",
       "      <td>0.133158</td>\n",
       "      <td>0.398403</td>\n",
       "      <td>0.101776</td>\n",
       "      <td>0.133158</td>\n",
       "      <td>0.398403</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_test  operating_cost  score_val  \\\n",
       "0     LightGBMLarge_BAG_L1_FULL    0.371108        -4157000        NaN   \n",
       "1               LightGBM_BAG_L1    0.349669        -4397000   0.366117   \n",
       "2          LightGBM_BAG_L1_FULL    0.348052        -4327000        NaN   \n",
       "3  RandomForestEntr_BAG_L1_FULL    0.346354        -4576000        NaN   \n",
       "4       RandomForestEntr_BAG_L1    0.346354        -4576000   0.325664   \n",
       "\n",
       "   pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0        0.044924            NaN   3.855480                 0.044924   \n",
       "1        0.211080       0.053773  17.062408                 0.211080   \n",
       "2        0.024526            NaN   0.809883                 0.024526   \n",
       "3        0.091884       0.133158   0.398403                 0.091884   \n",
       "4        0.101776       0.133158   0.398403                 0.101776   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                     NaN           3.855480            1       True   \n",
       "1                0.053773          17.062408            1       True   \n",
       "2                     NaN           0.809883            1       True   \n",
       "3                0.133158           0.398403            1       True   \n",
       "4                0.133158           0.398403            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0         33  \n",
       "1          4  \n",
       "2         26  \n",
       "3         28  \n",
       "4          6  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test, extra_metrics=[my_scorer], silent=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('automl-course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe540bd4b5a6de66905331bc10682f07f90eff03729ec2ebc0f9e32a56d7316a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
